{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import tqdm.notebook as tqdm\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import average_precision_score, \\\n",
    "    balanced_accuracy_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, \\\n",
    "    StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from correlation_threshold import CorrelationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='sans-serif')\n",
    "sns.set_palette(['#6da7de', '#9e0059', '#dee000', '#d82222', '#5ea15d',\n",
    "                 '#943fa6', '#63c5b5', '#ff38ba', '#eb861e', '#ee266d'])\n",
    "sns.set_context('paper', font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular descriptor feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = pd.read_csv('../data/compound_smiles.csv')\n",
    "mols = compounds['SMILES (Canonical)'].apply(Chem.MolFromSmiles)\n",
    "clss = compounds['Skin'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features using Mordred.\n",
    "mordred_calculator = Calculator(descriptors, ignore_3D=True)\n",
    "# Exclude features that contain non-numeric values.\n",
    "features = pd.DataFrame(mordred_calculator.pandas(mols)\n",
    "                        .select_dtypes(exclude='object')\n",
    "                        .astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 100\n",
    "test_size = 0.2\n",
    "\n",
    "variance_threshold = 0.05\n",
    "correlation_threshold = 0.95\n",
    "n_trees = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Repeatedly evaluate the model to estimate its performance.\n",
    "accuracies_train = np.zeros(n_splits, np.float32)\n",
    "accuracies_test = np.zeros(n_splits, np.float32)\n",
    "average_precisions_train = np.zeros(n_splits, np.float32)\n",
    "average_precisions_test = np.zeros(n_splits, np.float32)\n",
    "roc_aucs_train = np.zeros(n_splits, np.float32)\n",
    "roc_aucs_test = np.zeros(n_splits, np.float32)\n",
    "interval = np.linspace(0, 1, 101, dtype=np.float32)\n",
    "tprs_train = np.zeros((n_splits, 101), np.float32)\n",
    "tprs_test = np.zeros((n_splits, 101), np.float32)\n",
    "precisions_train = np.zeros((n_splits, 101), np.float32)\n",
    "precisions_test = np.zeros((n_splits, 101), np.float32)\n",
    "best_max_depth = np.zeros(n_splits, np.uint8)\n",
    "for i, (train_index, test_index) in tqdm.tqdm(\n",
    "        enumerate(\n",
    "            StratifiedShuffleSplit(\n",
    "                n_splits, test_size=test_size, random_state=42).split(\n",
    "                features.values, clss)),\n",
    "        desc='Cross-validation', total=n_splits):\n",
    "    features_train = features.values[train_index]\n",
    "    features_test = features.values[test_index]\n",
    "    clss_train, clss_test = clss[train_index], clss[test_index]\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        Pipeline([\n",
    "            ('variance_threshold', VarianceThreshold(variance_threshold)),\n",
    "            ('correlation_threshold', CorrelationThreshold(\n",
    "                correlation_threshold)),\n",
    "            ('classify', RandomForestClassifier(\n",
    "                n_estimators=n_trees, random_state=42))]),\n",
    "        param_grid={'classify__max_depth': np.arange(3, 9, 1)},\n",
    "        cv=StratifiedShuffleSplit(n_splits, test_size=test_size,\n",
    "                                  random_state=42))\n",
    "    \n",
    "    grid_search.fit(features_train, clss_train)\n",
    "    pred_train = grid_search.predict_proba(features_train)[:, 1]\n",
    "    pred_test = grid_search.predict_proba(features_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics on the train and test data.\n",
    "    accuracies_train[i] = balanced_accuracy_score(\n",
    "            clss_train, np.asarray(pred_train > 0.5, np.int))\n",
    "    accuracies_test[i] = balanced_accuracy_score(\n",
    "            clss_test, np.asarray(pred_test > 0.5, np.int))\n",
    "    average_precisions_train[i] = average_precision_score(\n",
    "        clss_train, pred_train)\n",
    "    average_precisions_test[i] = average_precision_score(\n",
    "        clss_test, pred_test)\n",
    "    roc_aucs_train[i] = roc_auc_score(clss_train, pred_train)\n",
    "    roc_aucs_test[i] = roc_auc_score(clss_test, pred_test)\n",
    "    fpr_train, tpr_train, _ = roc_curve(clss_train, pred_train)\n",
    "    tprs_train[i] = np.interp(interval, fpr_train, tpr_train)\n",
    "    fpr_test, tpr_test, _ = roc_curve(clss_test, pred_test)\n",
    "    tprs_test[i] = np.interp(interval, fpr_test, tpr_test)\n",
    "    precision_train, recall_train, _ = precision_recall_curve(\n",
    "        clss_train, pred_train)\n",
    "    precisions_train[i] = np.interp(\n",
    "        interval, recall_train[::-1], precision_train[::-1])\n",
    "    precision_test, recall_test, _ = precision_recall_curve(\n",
    "        clss_test, pred_test)\n",
    "    precisions_test[i] = np.interp(\n",
    "        interval, recall_test[::-1], precision_test[::-1])\n",
    "    \n",
    "    # Save optimal hyperparameter(s).\n",
    "    best_max_depth[i] = (grid_search.best_estimator_\n",
    "                         .named_steps['classify'].max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {'accuracy_train': np.mean(accuracies_train),\n",
    "         'accuracy_std_train': np.std(accuracies_train),\n",
    "         'average_precision_train': np.mean(average_precisions_train),\n",
    "         'average_precision_std_train': np.std(average_precisions_train),\n",
    "         'roc_auc_train': np.mean(roc_aucs_train),\n",
    "         'roc_auc_std_train': np.std(roc_aucs_train),\n",
    "         'tpr_mean_train': np.mean(tprs_train, axis=0),\n",
    "         'tpr_std_train': np.std(tprs_train, axis=0),\n",
    "         'precision_mean_train': np.mean(precisions_train, axis=0),\n",
    "         'precision_std_train': np.std(precisions_train, axis=0),\n",
    "        \n",
    "         'accuracy_test': np.mean(accuracies_test),\n",
    "         'accuracy_std_test': np.std(accuracies_test),\n",
    "         'average_precision_test': np.mean(average_precisions_test),\n",
    "         'average_precision_std_test': np.std(average_precisions_test),\n",
    "         'roc_auc_test': np.mean(roc_aucs_test),\n",
    "         'roc_auc_std_test': np.std(roc_aucs_test),\n",
    "         'tpr_mean_test': np.mean(tprs_test, axis=0),\n",
    "         'tpr_std_test': np.std(tprs_test, axis=0),\n",
    "         'precision_mean_test': np.mean(precisions_test, axis=0),\n",
    "         'precision_std_test': np.std(precisions_test, axis=0),\n",
    "        \n",
    "         'max_depth': scipy.stats.mode(best_max_depth)[0][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {stats[\"accuracy_test\"]:.3f} ± '\n",
    "      f'{stats[\"accuracy_std_test\"]:.3f}')\n",
    "print(f'AUROC: {stats[\"roc_auc_test\"]:.3f} ± '\n",
    "      f'{stats[\"roc_auc_std_test\"]:.3f}')\n",
    "print(f'Average precision: {stats[\"average_precision_test\"]:.3f} ± '\n",
    "      f'{stats[\"average_precision_std_test\"]:.3f}')\n",
    "print(f'Optimal number of maximum depth (mode): {stats[\"max_depth\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the optimal model on the entire dataset and export.\n",
    "classifier = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(variance_threshold)),\n",
    "    ('correlation_threshold', CorrelationThreshold(correlation_threshold)),\n",
    "    ('classify', RandomForestClassifier(n_estimators=n_trees,\n",
    "                                        max_depth=stats['max_depth'],\n",
    "                                        random_state=42))])\n",
    "classifier.fit(features.values, clss)\n",
    "_ = joblib.dump(classifier, 'rf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # Golden ratio.\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "interval = np.linspace(0, 1, 101)\n",
    "tpr_test = stats['tpr_mean_test']\n",
    "tpr_test[0], tpr_test[-1] = 0, 1\n",
    "ax.plot(interval, tpr_test,\n",
    "        label=f'AUC = {stats[\"roc_auc_test\"]:.3f} '\n",
    "              f'± {stats[\"roc_auc_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, tpr_test - stats['tpr_std_test'],\n",
    "                tpr_test + stats['tpr_std_test'], alpha=0.2)\n",
    "        \n",
    "ax.plot([0, 1], [0, 1], c='black', ls='--')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('roc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # Golden ratio.\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "        \n",
    "precision_test = stats['precision_mean_test']\n",
    "ax.plot(interval, precision_test,\n",
    "        label=f'Avg precision = '\n",
    "              f'{stats[\"average_precision_test\"]:.3f} ± '\n",
    "              f'{stats[\"average_precision_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, precision_test - stats['precision_std_test'],\n",
    "                precision_test + stats['precision_std_test'], alpha=0.2)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('pr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    classifier, features.values, clss, train_sizes=np.linspace(0.2, 1.0, 10),\n",
    "    cv=StratifiedShuffleSplit(n_splits, test_size=0.2, random_state=42),\n",
    "    scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # Golden ratio.\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', label='Test score')\n",
    "ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                test_scores_mean + test_scores_std, alpha=0.2)\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', label='Training score')\n",
    "ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                train_scores_mean + train_scores_std, alpha=0.2)\n",
    "\n",
    "ax.set_xlabel('Number of training examples')\n",
    "ax.set_ylabel('AUROC')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances.\n",
    "predict_proba = lambda x: classifier.predict_proba(x)[:,1]\n",
    "features_median = features.median().values.reshape((1, -1))\n",
    "explainer = shap.KernelExplainer(\n",
    "    predict_proba, shap.kmeans(features.values, 50), link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # Golden ratio.\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "importances = np.abs(np.mean(shap_values, axis=0))\n",
    "order = np.argsort(importances)[::-1]\n",
    "sns.barplot(x=np.arange(20), y=importances[order][:20], color='#6da7de')\n",
    "\n",
    "ax.set_xticklabels(features.columns.values[order][:20], rotation=90)\n",
    "ax.set_ylabel('SHAP feature importance')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('feature_importance_global.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 7\n",
    "height = width / 1.618    # Golden ratio.\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "column_i = features.columns.get_loc('MW')\n",
    "ax.scatter(features['MW'], shap_values[:, column_i])\n",
    "\n",
    "ax.set_xlabel('Molecular weight')\n",
    "ax.set_ylabel('SHAP value')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('feature_importance_mw.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compounds = pd.DataFrame({\n",
    "    'compound': ['diphenhydramine', 'diphenhydramine N-hexose'],\n",
    "    'smiles': ['CN(CCOC(c1ccccc1)c1ccccc1)C',\n",
    "               'C[N+](CCOC(C1=CC=CC=C1)C2=CC=CC=C2)(OC3OC(CO)C(O)C(O)C3O)C']})\n",
    "test_features = pd.DataFrame(\n",
    "    mordred_calculator.pandas(test_compounds['smiles']\n",
    "                              .apply(Chem.MolFromSmiles))\n",
    "    [features.columns].astype(np.float32))\n",
    "test_pred = classifier.predict_proba(test_features.values)[:, 1]\n",
    "test_shap = explainer.shap_values(test_features)\n",
    "\n",
    "for i, compound in enumerate(test_compounds['compound']):\n",
    "    print(f'Score for {compound}: {test_pred[i]:.2f}')\n",
    "    shap.plots.force(explainer.expected_value, test_shap[i],\n",
    "                     test_features.iloc[i].round(2).astype(str),\n",
    "                     matplotlib=True, show=False,\n",
    "                     contribution_threshold=0.02)\n",
    "    plt.savefig(f'shap_{compound}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(\n",
    "    (stats, (train_sizes, train_scores, test_scores), shap_values),\n",
    "    'drugs_epidermis.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
